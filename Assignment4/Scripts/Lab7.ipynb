{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Survival Modeling\n",
    "\n",
    "## Overview\n",
    "This lab focuses on survival modeling techniques and their applications in statistical analysis. The primary topics covered include Cox regression, regularized Cox regression, Random Survival Forest, Kaplan-Meier curve analysis, and multiple testing correction.\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "### 1. Survival Models\n",
    "Survival models analyze time-to-event data, allowing us to estimate hazard rates and survival probabilities. Below are the key models explored:\n",
    "\n",
    "| Model                      | Description |\n",
    "|----------------------------|-------------|\n",
    "| **Cox Regression**         | A semi-parametric model that estimates the hazard ratio while accounting for covariates. |\n",
    "| **Regularized Cox Regression** | A variant of Cox regression incorporating LASSO or Ridge penalties to handle high-dimensional data. |\n",
    "| **Random Survival Forest** | A non-parametric ensemble learning method that uses decision trees to model survival data. |\n",
    "\n",
    "#### Implementation Notes\n",
    "- Cox regression: Implemented using `lifelines` or `statsmodels` in Python.\n",
    "- Regularized Cox regression: Uses L1/L2 penalties with `scikit-survival` or `sksurv`.\n",
    "- Random Survival Forest: Implemented via `scikit-survival` or `sksurv` with hyperparameter tuning.\n",
    "\n",
    "### 2. Kaplan-Meier Curve Analysis\n",
    "The Kaplan-Meier estimator is a non-parametric method for estimating survival probabilities over time.\n",
    "\n",
    "<img src=\"km-curve.png\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "\n",
    "| Feature                | Description |\n",
    "|------------------------|-------------|\n",
    "| **Survival Function**  | Estimates the probability of survival beyond a certain time point. |\n",
    "| **Log-Rank Test**      | Compares survival distributions across groups. |\n",
    "| **Visualization**      | Stepwise function plotted using `matplotlib` or `lifelines`. |\n",
    "\n",
    "#### Interpretation\n",
    "- A steep drop in the Kaplan-Meier curve suggests high event occurrence at that time point.\n",
    "- Log-rank test helps assess statistical differences between survival curves of different groups.\n",
    "\n",
    "### 3. Dataset Usage\n",
    "While we have skeleton code in the notebook using pre-loaded datasets from `lifelines` and `sksurv` packages, we will also explore a publicly available dataset from [NSCLC Radiogenomics](https://www.cancerimagingarchive.net/collection/nsclc-radiogenomics/). This dataset provides imaging and clinical data for non-small cell lung cancer (NSCLC) patients, allowing us to apply survival analysis techniques in a real-world context.\n",
    "\n",
    "\n",
    "## Summary\n",
    "- **Cox models** estimate hazard ratios for covariates.\n",
    "- **Kaplan-Meier curves** visualize survival probabilities over time.\n",
    "- **Real-world dataset** from NSCLC Radiogenomics allows practical application of survival modeling.\n",
    "\n",
    "Each section includes hands-on coding exercises and questions for deeper exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Survival Models\n",
    "\n",
    "### 1.1 Cox Regression\n",
    "\n",
    "We will start by implementing Cox regression for survival analysis. We will also explore different parameters and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.datasets import load_rossi\n",
    "\n",
    "# Load the Rossi dataset\n",
    "data = load_rossi()\n",
    "\n",
    "# Fit the Cox proportional hazards model\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(data, duration_col='week', event_col='arrest')\n",
    "# need to define duration and event columns.\n",
    "# Print the summary of the model\n",
    "cph.print_summary()\n",
    "\n",
    "# Plot the coefficients\n",
    "cph.plot()\n",
    "plt.title('Cox Regression Coefficients')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoxPHFitter?\n",
    "# load_rossi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. How do we interpret the hazard ratios derived from the Cox model, and what do they imply about risk factors?\n",
    "2. What assumptions does the Cox proportional hazards model make, and how can we test if they hold? HINT: check this [link](https://lifelines.readthedocs.io/en/latest/jupyter_notebooks/Proportional%20hazard%20assumption.html).\n",
    "3. What happens to the model performance if you include or exclude certain covariates?\n",
    "4. What happens to the model performance if you change the `baseline_estimation_method`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Lasso for Censored Data\n",
    "\n",
    "Now, we will implement Lasso for censored data using the Cox regression model with L1 regularization. We will also explore different parameters and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from lifelines.datasets import load_rossi\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# Load the Rossi dataset\n",
    "data = load_rossi()\n",
    "\n",
    "# Prepare the data for sksurv\n",
    "X = data.drop(columns=['week', 'arrest']).astype(float)\n",
    "y = np.array([(bool(event), time) for event, time in zip(data['arrest'], data['week'])], dtype=[('event', bool), ('time', float)])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the Cox proportional hazards model with L1 regularization\n",
    "cph_lasso = CoxnetSurvivalAnalysis(l1_ratio=1.0)\n",
    "cph_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict the risk scores on the test set\n",
    "risk_scores = cph_lasso.predict(X_test)\n",
    "\n",
    "# Calculate the concordance index\n",
    "c_index = concordance_index_censored(y_test['event'], y_test['time'], risk_scores)[0]\n",
    "print(f'Concordance Index: {c_index:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. How does the L1 regularization affect the coefficients of the Cox regression model? HINT: examine `cph_lasso.coef_`.\n",
    "2. How does penalizing the Cox model (e.g., L1/L2 regularization) impact variable selection and model performance?\n",
    "3. What happens to the model performance if you change the `l1_ratio`?\n",
    "4. What are the differences in model performance and interpretability between `CoxPHFitter` from `lifelines` and `CoxnetSurvivalAnalysis` from `sksurv`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Random Survival Forest\n",
    "\n",
    "Next, we will implement a Random Survival Forest for survival analysis. We will also explore different parameters and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.datasets import load_whas500\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Load the WHAS500 dataset\n",
    "data_x, data_y = load_whas500()\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder()\n",
    "data_x = encoder.fit_transform(data_x)\n",
    "\n",
    "# Train a Random Survival Forest model\n",
    "rsf = RandomSurvivalForest(n_estimators=100, random_state=42)\n",
    "rsf.fit(data_x, data_y)\n",
    "\n",
    "# please refer to https://scikit-survival.readthedocs.io/en/stable/user_guide/random-survival-forest.html\n",
    "result = permutation_importance(rsf, data_x, data_y, n_repeats=15, random_state=42)\n",
    "feature_importance = pd.DataFrame(\n",
    "         {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=data_x.columns,\n",
    ").sort_values(by=\"importances_mean\", ascending=False)\n",
    "\n",
    "# Sort by importances_mean and plot\n",
    "feature_importance = feature_importance.sort_values(by=\"importances_mean\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(feature_importance.index, feature_importance['importances_mean'], xerr=feature_importance['importances_std'], align='center')\n",
    "plt.xlabel('Mean Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomSurvivalForest?\n",
    "# load_whas500?\n",
    "# permutation_importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. How do the feature importances from the Random Survival Forest model interpret the relationship between covariates and survival time?\n",
    "2. What happens to the model performance if you change the number of trees (`n_estimators`)?\n",
    "3. How does the choice of dataset affect the Random Survival Forest results and their interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kaplan-Meier Curve Analysis\n",
    "\n",
    "We will perform Kaplan-Meier curve analysis to visualize and interpret survival probabilities over time. We will also explore different visualization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Load the Rossi dataset\n",
    "data = load_rossi()\n",
    "\n",
    "# Fit the Kaplan-Meier estimator\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(data['week'], event_observed=data['arrest'])\n",
    "\n",
    "# Plot the Kaplan-Meier curve\n",
    "kmf.plot_survival_function()\n",
    "plt.title('Kaplan-Meier Curve')\n",
    "plt.xlabel('Time (weeks)')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. What happens to the Kaplan-Meier curves if you stratify the data by different covariates?\n",
    "2. How can you extract median survival time from a Kaplan-Meier estimator in `lifelines`?\n",
    "3. How do confidence intervals impact the interpretation of Kaplan-Meier curves?\n",
    "4. How can you compare multiple survival groups using statistical tests such as the log-rank test? HINT: check this [link](https://lifelines.readthedocs.io/en/latest/lifelines.statistics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaplanMeierFitter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Usage\n",
    "\n",
    "On Blackboard, you'll find a folder titled 'NSCLC Dataset'. In here, you'll find two spreadsheets:\n",
    "- `tpm_counts.csv` which contains RNA sequencing data in transcripts per million (TPM);\n",
    "- `clinical.csv` which contains the associated clinical data for the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = pd.read_csv('NSCLC Dataset/tpm_counts.csv')\n",
    "\n",
    "# describe the data\n",
    "rna.head()\n",
    "# rna.describe()   # <-- will show the summary statistics of the data, but not recommended as it will take awhile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical = pd.read_csv('NSCLC Dataset/clinical.csv')\n",
    "\n",
    "# describe the data\n",
    "clinical.head()\n",
    "# clinical.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try incorporating clinical data from `clinical.csv` into the analysis. To do this, follow these steps:\n",
    "1. Create a `time` column by calculating the number of days between **'Date of Last Known Alive'** and **'CT Date'** (both in MM/DD/YYYY format).\n",
    "2. Convert the **'Survival Status'** column into a boolean event indicator, where **Death** corresponds to `True` (event observed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sksurv.util import Surv\n",
    "\n",
    "clinical_data = clinical.copy()\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "clinical_data[\"Date of Last Known Alive\"] = pd.to_datetime(clinical_data[\"Date of Last Known Alive\"], format=\"%m/%d/%Y\")\n",
    "clinical_data[\"CT Date\"] = pd.to_datetime(clinical_data[\"CT Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "# Calculate time in days\n",
    "clinical_data[\"time\"] = (clinical_data[\"Date of Last Known Alive\"] - clinical_data[\"CT Date\"]).dt.days - clinical_data['Days between CT and surgery']\n",
    "\n",
    "# Convert event column to boolean (Death = True, Alive = False)\n",
    "clinical_data[\"event\"] = clinical_data[\"Survival Status\"].apply(lambda x: True if x == \"Death\" else False)\n",
    "\n",
    "# Convert to sksurv structured array format\n",
    "survival_data = Surv.from_dataframe(\"event\", \"time\", clinical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "Explore other survival analysis techniques such as:\n",
    "- Accelerated Failure Time (AFT) models\n",
    "- Competing risks models\n",
    "- Time-dependent covariates in Cox regression\n",
    "\n",
    "Compare their performance and interpretation with the techniques covered in this lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
